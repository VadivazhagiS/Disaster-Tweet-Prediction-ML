# *Disaster-Tweet-Prediction-ML*
The Disaster Tweet Prediction project utilizes natural language processing (NLP) and machine learning techniques to classify tweets as either disaster-related or not. The model is trained on a dataset of labeled tweets and uses various machine learning algorithms to achieve this classification.
## *Data exploration* 
In this step, we analyze the dataset to understand its structure, features, and distribution. Exploratory Data Analysis (EDA) techniques are employed to gain insights into the data.
## *text preprocessing*
Text preprocessing involves cleaning and transforming the raw text data into a suitable format for machine learning. This includes tasks such as removing special characters, converting text to lowercase, and handling stop words.
## *feature extraction*
Feature extraction involves converting the preprocessed text data into numerical features that can be fed into machine learning models. Techniques such as TF-IDF (Term Frequency-Inverse Document Frequency) or word embeddings like Word2Vec can be used.
## *data splitting*
The dataset is split into training and testing sets. The training set is used to train the machine learning models, while the testing set is used to evaluate the model's performance.
## *model selection*
In this step, various machine learning models are selected and trained using the preprocessed and feature-extracted data. Different models like Logistic Regression, Random Forest, Support Vector Machine (SVM), and Multinomial Naive Bayes can be evaluated and compared for their predictive performance.
